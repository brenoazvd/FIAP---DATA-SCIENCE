# -*- coding: utf-8 -*-
"""desafio deep learning 06/05/2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NGJYdzLxmZG7Uny54y8l7bDrxLkcvSiV

Classificador de Espécies de Íris com Redes Neurais e Normalização de Dados

Breno Azevedo
"""

from sklearn.neural_network import MLPClassifier
from sklearn import datasets
import pandas as pd
import numpy as np

iris = datasets.load_iris()

entradas = iris.data #Pega as entradas
saidas = iris.target #Pega a saída

df = pd.DataFrame(iris.data, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])

print(df)

df['class'] = iris.target
df

"""(pré-processamento de dados)"""

def normalizar(x):
  return (x - np.min(x))/(np.max(x) - np.min(x))

def padronizar(x):
  return (x -np.mean(x))/np.std(x)

from scipy.stats import shapiro
# Verificar normalidade usando o teste de Shapiro-Wilk
def verifica_normalidade(dataframe, coluna):
    coluna_data = dataframe[coluna]
    # Realizar o teste de Shapiro-Wilk
    statistic, p_valor = shapiro(coluna_data)
    # Definir o nível de significância
    nivel_significancia = 0.1
    # Verificar se a hipótese nula de normalidade pode ser rejeitada
    if p_valor > nivel_significancia:
        print(f"A coluna '{coluna}' segue uma distribuição normal")
        return True
    else:
        print(f"A coluna '{coluna}' não segue uma distribuição normal")
        return False

# Chamando a função para verificar normalidade
for coluna in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:
  if verifica_normalidade(df, coluna):
    df[coluna] = padronizar(df[coluna])#se for distribuição normal, padroniza
  else:#senão, normaliza
    df[coluna] = normalizar(df[coluna])

df

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score


X = df.drop('class', axis=1)#entradas
y = df['class']#classe (saída)

# Dividir o conjunto de dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

#A gente sempre usa as entradas de dados como X máiusculo
# (idica que são mais de uma entra) entradas: todas as outras colunas com exceção 'sobreviveu'

redeneural = MLPClassifier(verbose=True, #Para printar a "epóca"(deixa lerdo) false=datasets reais
                           max_iter=14000, #máximo de interações
                           tol=0.000001,#tolerância
                           activation='relu',
                           hidden_layer_sizes=(3),
                           learning_rate_init=0.0001)

redeneural.fit(X_train,y_train)

from sklearn.metrics import accuracy_score

y_pred = redeneural.predict(X_test)

#Avaliar a acurácia do modelo
accuracy = accuracy_score(y_test, y_pred)
print('Acurácia do modelo kNN:', accuracy)

