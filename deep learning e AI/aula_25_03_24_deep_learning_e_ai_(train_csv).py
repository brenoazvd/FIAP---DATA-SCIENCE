# -*- coding: utf-8 -*-
"""Aula 25/03/24_Deep Learning e AI (train.csv)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gHM6ihgeO1XR9FlNg-oS4uA46pTIzTB8

## Classificação de Sobrevivência com Pré-Processamento de Dados e k-NN
## Breno Azevedo
"""

import pandas as pd
import numpy as np

def normalizar(x): #X será uma lista de valores numéricos
  return (x - np.min(x))/(np.max(x) - np.min(x))

def padronizar(x):
    return (x -np.mean(x))/np.std(x)


df = pd.read_csv("/home/train.csv")

df = df.drop(columns=['id', 'nome', 'bilhete'])

df

df.info()

df.sexo.unique()#dado categórico

df.classe_social.unique()#dado categórico

df.idade.unique()#dado númerico - númericos continuos

df.isna().sum()

df = df.drop('cabine', axis=1)
df.head(50)

df.shape #retorna o formato do dataset

df = pd.get_dummies(df, columns=['classe_social', 'sexo', 'embarque'])

df

df = df.dropna()
df

df.shape

import seaborn as sb
sb.pairplot(df[['idade',  'parentes', 'dependentes' ,'tarifa', 'sobreviveu']], hue='sobreviveu')

from scipy.stats import shapiro
# Verificar normalidade usando o teste de Shapiro-Wilk
def verifica_normalidade(dataframe, coluna):
    coluna_data = dataframe[coluna]
    # Realizar o teste de Shapiro-Wilk
    statistic, p_valor = shapiro(coluna_data)
    # Definir o nível de significância
    nivel_significancia = 0.1
    # Verificar se a hipótese nula de normalidade pode ser rejeitada
    if p_valor > nivel_significancia:
        print(f"A coluna '{coluna}' segue uma distribuição normal")
        return True
    else:
        print(f"A coluna '{coluna}' não segue uma distribuição normal")
        return False

# Chamando a função para verificar normalidade
for coluna in ['idade', 'parentes', 'dependentes',  'tarifa'  ]: #númericas continuas
  if verifica_normalidade(df, coluna):
    df[coluna] = padronizar(df[coluna])#se for distribuição normal, padroniza
  else:#senão, normaliza
    df[coluna] = normalizar(df[coluna])

df

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

y = df['sobreviveu']
X = df.drop('sobreviveu', axis=1)

# Dividir o conjunto de dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#A gente sempre usa as entradas de dados como X máiusculo
# (idica que são mais de uma entra) entradas: todas as outras colunas com exceção 'sobreviveu'

#Comum: 70% amostras para treino -> no máximo 80% treino
#Comum 30% amostras para teste -> no mín 20% teste

X.shape[0]**0.5

knn = KNeighborsClassifier(n_neighbors=27)

#treinar o modelo kNN
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

#Avaliar a acurácia do modelo
accuracy = accuracy_score(y_test, y_pred)
print('Acurácia do modelo kNN:', accuracy)

#testando o k ideal
for k in range(3,51,2):
  knn = KNeighborsClassifier(n_neighbors=k)
  # Treinar o modelo kNN
  knn.fit(X_train, y_train)
  y_pred = knn.predict(X_test)

  # Avaliar a acurácia do modelo
  accuracy = accuracy_score(y_test, y_pred)
  print(f'Acurácia para k={k}:', accuracy)

#                                   0  1  2
def distancia_euclidiana(A, B): # A=[3, 6, 9]
#                                B=[7, 8, 12]
  if len(A) == len(B):
    total = 0
    for i in range(0, len(A)):
      total +- (B[i]- A[i])**2
    return total**0.5
  print("erro de dimensões")
  return 0

pontoA = [3, 6, 9]
pontoB = [7, 8, 12]
distancia_euclidiana(pontoA, pontoB)

